{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from xbatcher import BatchGenerator\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from utils.general import load_config\n",
    "\n",
    "config = load_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model': {'architecture': 'SRResNet',\n",
       "  'large_kernel_size': 9,\n",
       "  'small_kernel_size': 3,\n",
       "  'n_channels': 64,\n",
       "  'n_blocks': 16,\n",
       "  'scaling_factor': 8},\n",
       " 'training': {'streaming': False,\n",
       "  'learning_rate': 0.01,\n",
       "  'batch_size': 32,\n",
       "  'epochs': 100,\n",
       "  'optimizer': 'Adam',\n",
       "  'loss_function': 'mse_loss',\n",
       "  'devices': [0],\n",
       "  'accelerator': 'gpu',\n",
       "  'deterministic': True,\n",
       "  'seed': 42},\n",
       " 'dataset': {'hr_zarr_url': 'https://cacheb.dcms.destine.eu/d1-climate-dt/ScenarioMIP-SSP3-7.0-IFS-NEMO-0001-high-sfc-v0.zarr',\n",
       "  'lr_zarr_url': 'https://cacheb.dcms.destine.eu/d1-climate-dt/ScenarioMIP-SSP3-7.0-IFS-NEMO-0001-standard-sfc-v0.zarr',\n",
       "  'time_range': '2024-10',\n",
       "  'start_date': '2020-01-01',\n",
       "  'end_date': '2020-01-10',\n",
       "  'latitude_range': [35.0, 71.0],\n",
       "  'longitude_range': [-25.0, 40.0],\n",
       "  'data_variable': ['t2m'],\n",
       "  'data_target': ['t2m'],\n",
       "  'unit': 'Temperature (C)'},\n",
       " 'validation': {'val_split_ratio': 0.3},\n",
       " 'checkpoint': {'monitor': 'val_ssim',\n",
       "  'mode': 'max',\n",
       "  'filename': 'best-val-ssim-{epoch:02d}-{val_ssim:.2f}',\n",
       "  'save_top_k': 1},\n",
       " 'visualization': {'color_map': 'YlOrRd'}}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "start_date = config['dataset']['start_date']\n",
    "end_date = config['dataset']['end_date']\n",
    "data_vars = config['dataset']['data_variable']\n",
    "data = xr.open_dataset(\n",
    "    config[\"dataset\"][\"hr_zarr_url\"],\n",
    "    engine=\"zarr\", storage_options={\"client_kwargs\": {\"trust_env\": \"true\"}},\n",
    "    chunks={})\n",
    "\n",
    "\n",
    "latitude_range = tuple(config[\"dataset\"][\"latitude_range\"])\n",
    "longitude_range = tuple(config[\"dataset\"][\"longitude_range\"])\n",
    "data = data.sel(time=slice(start_date, end_date))\n",
    "data = data.sel(latitude=slice(latitude_range[0],latitude_range[1]),\n",
    "                longitude=slice(longitude_range[0],longitude_range[1]),\n",
    "                time=slice(start_date,end_date))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Frozen({'time': 24, 'latitude': 819, 'longitude': 1479})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data_vars = list(data.data_vars)\n",
    "\n",
    "data = data[data_vars]\n",
    "data.sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "819"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.sizes['latitude']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "GPU_DEVICE = 0\n",
    "device = torch.device(\"cuda\",GPU_DEVICE)\n",
    "batch_generator = BatchGenerator(data, input_dims={\"time\": config['training']['batch_size'],\n",
    "                                                   \"latitude\":  data.sizes['latitude'],\n",
    "                                                   \"longitude\": data.sizes['longitude']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frozen({'time': 32, 'latitude': 819, 'longitude': 1479})\n",
      "torch.Size([32, 1, 819, 1479])\n"
     ]
    }
   ],
   "source": [
    "# Iterate through one batch\n",
    "for batch in batch_generator:\n",
    "\n",
    "    data  = batch.load()\n",
    "    print(data.sizes)\n",
    "    data = data.to_array().values\n",
    "    data = torch.tensor(data)\n",
    "    data = torch.permute(data, (1, 0, 2, 3))\n",
    "    print(data.shape)\n",
    "    data.to(device)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import time\n",
    "import numpy as np\n",
    "from xbatcher import BatchGenerator\n",
    "from utils.general import load_config\n",
    "\n",
    "config = load_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frozen({'time': 8, 'latitude': 819, 'longitude': 1479})\n",
      "Frozen({'time': 8, 'latitude': 819, 'longitude': 1479})\n",
      "Frozen({'time': 8, 'latitude': 819, 'longitude': 1479})\n",
      "Frozen({'time': 8, 'latitude': 819, 'longitude': 1479})\n",
      "Frozen({'time': 8, 'latitude': 819, 'longitude': 1479})\n",
      "Frozen({'time': 8, 'latitude': 819, 'longitude': 1479})\n",
      "Frozen({'time': 8, 'latitude': 819, 'longitude': 1479})\n",
      "Frozen({'time': 8, 'latitude': 819, 'longitude': 1479})\n",
      "Frozen({'time': 8, 'latitude': 819, 'longitude': 1479})\n",
      "Frozen({'time': 8, 'latitude': 819, 'longitude': 1479})\n",
      "Frozen({'time': 8, 'latitude': 819, 'longitude': 1479})\n",
      "Frozen({'time': 8, 'latitude': 819, 'longitude': 1479})\n",
      "Frozen({'time': 8, 'latitude': 819, 'longitude': 1479})\n",
      "Frozen({'time': 8, 'latitude': 819, 'longitude': 1479})\n",
      "Frozen({'time': 8, 'latitude': 819, 'longitude': 1479})\n",
      "Frozen({'time': 8, 'latitude': 819, 'longitude': 1479})\n",
      "Frozen({'time': 8, 'latitude': 819, 'longitude': 1479})\n",
      "Frozen({'time': 8, 'latitude': 819, 'longitude': 1479})\n",
      "Frozen({'time': 8, 'latitude': 819, 'longitude': 1479})\n",
      "Frozen({'time': 8, 'latitude': 819, 'longitude': 1479})\n",
      "Frozen({'time': 8, 'latitude': 819, 'longitude': 1479})\n",
      "Frozen({'time': 8, 'latitude': 819, 'longitude': 1479})\n",
      "Frozen({'time': 8, 'latitude': 819, 'longitude': 1479})\n",
      "Frozen({'time': 8, 'latitude': 819, 'longitude': 1479})\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "\n",
    "num_trials = 10  # Number of repetitions\n",
    "batch = 8\n",
    "\n",
    "# Open dataset once\n",
    "data = xr.open_dataset(\n",
    "    config[\"dataset\"][\"hr_zarr_url\"],\n",
    "    engine=\"zarr\", storage_options={\"client_kwargs\": {\"trust_env\": \"true\"}},\n",
    "    chunks={}\n",
    ")\n",
    "data = data.sel(\n",
    "    time=slice(\"2025-03-01\", \"2025-03-01\"),\n",
    "    latitude=slice(*config[\"dataset\"][\"latitude_range\"]),\n",
    "    longitude=slice(*config[\"dataset\"][\"longitude_range\"])\n",
    ")\n",
    "\n",
    "data_vars = list(data.data_vars)  # List of available variables\n",
    "\n",
    "num_vars_list = []\n",
    "time_avg_list = []\n",
    "time_std_list = []\n",
    "size_data = []\n",
    "\n",
    "for num_vars in range(1, min(len(data_vars), 10)):  # Avoid index error\n",
    "    selected_vars = data_vars[:num_vars]  # Select `num_vars` variables\n",
    "    hr_data_subset = data[selected_vars]\n",
    "    print(selected_vars)\n",
    "\n",
    "    batch_generator_hr = BatchGenerator(hr_data_subset, input_dims={\n",
    "        \"time\": batch,\n",
    "        \"latitude\": hr_data_subset.sizes[\"latitude\"],\n",
    "        \"longitude\": hr_data_subset.sizes[\"longitude\"]\n",
    "    })\n",
    "\n",
    "    times = []\n",
    "\n",
    "    for _ in range(num_trials):  # Run multiple trials\n",
    "        start_time = time.time()\n",
    "\n",
    "        for batch_data in batch_generator_hr:\n",
    "            data_batch = batch_data.load()\n",
    "            print(data_batch.sizes)\n",
    "\n",
    "\n",
    "        elapsed_time = time.time() - start_time\n",
    "        times.append(elapsed_time)\n",
    "\n",
    "        size = data_batch.nbytes / (1024 * 1024)  # Size in MB\n",
    "\n",
    "    avg_time = np.mean(times)\n",
    "    std_time = np.std(times)\n",
    "\n",
    "    num_vars_list.append(num_vars)\n",
    "    time_avg_list.append(avg_time)\n",
    "    time_std_list.append(std_time)\n",
    "    size_data.append(size)\n",
    "\n",
    "    print(f\"Num Vars: {num_vars}, Avg Time: {avg_time:.4f} sec, Std Dev: {std_time:.4f} sec\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_trials = 10  # Number of repetitions\n",
    "# num_vars_list = []\n",
    "# time_avg_list = []\n",
    "# time_std_list = []\n",
    "# size_data = []\n",
    "# batch = 8\n",
    "# for num_vars in range(1, 10):\n",
    "\n",
    "#     data = xr.open_dataset(\n",
    "#     config[\"dataset\"][\"hr_zarr_url\"],\n",
    "#     engine=\"zarr\", storage_options={\"client_kwargs\": {\"trust_env\": \"true\"}},\n",
    "#     chunks={})\n",
    "#     data_vars = list(data.data_vars)\n",
    "#     start_date = \"2025-03-01\"\n",
    "#     end_date = \"2025-03-01\"\n",
    "#     latitude_range = tuple(config[\"dataset\"][\"latitude_range\"])\n",
    "#     longitude_range = tuple(config[\"dataset\"][\"longitude_range\"])\n",
    "#     data = data.sel(time=slice(start_date, end_date))\n",
    "#     data = data.sel(latitude=slice(latitude_range[0],latitude_range[1]),\n",
    "#                     longitude=slice(longitude_range[0],longitude_range[1]))\n",
    "\n",
    "#     selected_vars = \"t2m\"\n",
    "\n",
    "#     hr_data_subset = data[selected_vars]  # Subset dataset\n",
    "#     batch_generator_hr = BatchGenerator(hr_data_subset, input_dims={\n",
    "#         \"time\": batch,\n",
    "#         \"latitude\": hr_data_subset.sizes[\"latitude\"],\n",
    "#         \"longitude\": hr_data_subset.sizes[\"longitude\"]\n",
    "#     })\n",
    "\n",
    "#     times = []\n",
    "\n",
    "#     for _ in range(num_trials):  # Run multiple trials\n",
    "#         start_time = time.time()\n",
    "\n",
    "#         for batch in batch_generator_hr:\n",
    "\n",
    "#             data_batch = batch.load()\n",
    "#             print(data_batch.shape)\n",
    "\n",
    "#         elapsed_time = time.time() - start_time\n",
    "#         times.append(elapsed_time)\n",
    "#         size = data_batch.nbytes / (1024*1024)\n",
    "#         # print(size)\n",
    "#         data_batch = 0\n",
    "#     avg_time = np.mean(times)\n",
    "#     std_time = np.std(times)\n",
    "\n",
    "#     num_vars_list.append(num_vars)\n",
    "#     time_avg_list.append(avg_time)\n",
    "#     time_std_list.append(std_time)\n",
    "#     size_data.append(size)\n",
    "#     print(f\"Num Vars: {num_vars}, Avg Time: {avg_time:.4f} sec, Std Dev: {std_time:.4f} sec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the results with error bars\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.errorbar(num_vars_list, time_avg_list, yerr=time_std_list, fmt='-o', capsize=4, label=\"Avg Time Â± Std Dev\")\n",
    "plt.xlabel(\"Number of Data Variables\")\n",
    "plt.ylabel(\"Time to Load (seconds)\")\n",
    "plt.title(\"Time to Load vs Number of Data Variables\")\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.savefig(\"load_vs_parameters.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "max_bandwidth_Mbps = 25000\n",
    "df = pd.DataFrame(data={\"climate_variables\":num_vars_list,\n",
    "                        \"time_avg\":time_avg_list,\n",
    "                        \"time_std\":time_std_list,\n",
    "                        \"size_data\":size_data})\n",
    "\n",
    "df[\"batch\"] = 64\n",
    "df[\"fps\"] = (df['climate_variables'] *  df[\"batch\"] / df[\"time_avg\"])\n",
    "df['bandwidth_MBps'] = df['size_data'] / df[\"time_avg\"]\n",
    "df['bandwidth_Mbps'] = df['size_data'] / df[\"time_avg\"] * 8\n",
    "df['max_bandwidth_Mbps'] = max_bandwidth_Mbps\n",
    "df[\"max_fps\"] = df['max_bandwidth_Mbps'] * df[\"fps\"] / df['bandwidth_Mbps']\n",
    "df[\"max_fps\"] = df['max_bandwidth_Mbps'] * df[\"fps\"] / df['bandwidth_Mbps']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "exp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
